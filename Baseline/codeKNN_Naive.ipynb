{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/abhishek/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def read_semcor_data(path):\n",
    "    \"\"\"\n",
    "    Read SemCor data from a directory and return a pandas DataFrame\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for subdir,_,files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('.naf'):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                tree = ET.parse(file_path)\n",
    "                root = tree.getroot()\n",
    "                context_pos_sent = []\n",
    "                context_sent = []\n",
    "                cont_dict = {}\n",
    "                for text in root.findall('./text'):\n",
    "                    for wf in text.findall('wf'):\n",
    "                        key = wf.attrib['id'] + \"%\" + file_path\n",
    "                        cont_dict[key] = wf.text\n",
    "\n",
    "                # add the pos tag to the context\n",
    "                for term in root.findall('./terms/term'):\n",
    "                    target_word = term.find(\"./span/target\").attrib['id'] + \"%\" + file_path\n",
    "                    pos = term.attrib['pos']\n",
    "                    context_pos_sent.append(cont_dict[target_word] + '_' + pos)\n",
    "                    context_sent.append(cont_dict[target_word])\n",
    "                context_pos = ' '.join(context_pos_sent)\n",
    "                context = ' '.join(context_sent)\n",
    "\n",
    "\n",
    "                for term in root.findall('./terms/term'):\n",
    "                    sense_number = term.find(\"./externalReferences/externalRef[@reftype='sense_number']\")\n",
    "                    lemma = term.attrib['lemma']\n",
    "                    lexical_key = term.find(\"./externalReferences/externalRef[@reftype='lexical_key']\")\n",
    "                    target_word = term.find(\"./span/target\").attrib['id']\n",
    "                    gloss = \"\"\n",
    "                    wn_index = lemma \n",
    "                    is_proper_gloss = False\n",
    "                    if lexical_key is not None:\n",
    "                        lexical_key = lexical_key.attrib['reference']\n",
    "                    if sense_number is not None and sense_number.attrib['reference'] != \"0\":\n",
    "                        wn_index = lemma + \"%\" + lexical_key \n",
    "\n",
    "                        synset_val = term.find(\"./externalReferences/externalRef[@reftype='synset']\")\n",
    "\n",
    "                        if synset_val is not None:\n",
    "                            synset_val = synset_val.attrib['reference']\n",
    "                            synset_obj = wn.synset_from_pos_and_offset(\n",
    "                                synset_val[-1], int(synset_val[6:-2]))\n",
    "                            synset_full = synset_obj.name()\n",
    "                            # print(synset_full)\n",
    "                            # synset_name = synset_full[:synset_full.index('.')]\n",
    "                            flg = 0\n",
    "                            for sense in wn.synsets(lemma):\n",
    "                                if sense.name() == synset_full:\n",
    "                                    gloss = sense.definition()\n",
    "                                    flg = 1\n",
    "                                    break\n",
    "                            if flg == 1:\n",
    "                                is_proper_gloss = True\n",
    "\n",
    "           \n",
    "                    data.append({\n",
    "                        \"file\": file_path,\n",
    "                        \"context\": context,\n",
    "                        \"context_pos\": context_pos,\n",
    "                        \"target_word\": target_word,\n",
    "                        \"gloss\": gloss,\n",
    "                        \"is_proper_gloss\": is_proper_gloss,\n",
    "                        \"wn_index\": wn_index,\n",
    "                        \"sense_full\": synset_full,\n",
    "                    })\n",
    "                        \n",
    "\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = \"../semcor3.0/brown2\"\n",
    "df = read_semcor_data(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>context</th>\n",
       "      <th>context_pos</th>\n",
       "      <th>target_word</th>\n",
       "      <th>gloss</th>\n",
       "      <th>is_proper_gloss</th>\n",
       "      <th>wn_index</th>\n",
       "      <th>sense_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w0</td>\n",
       "      <td>a human being</td>\n",
       "      <td>True</td>\n",
       "      <td>person%1:03:00::</td>\n",
       "      <td>person.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w2</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>for</td>\n",
       "      <td>person.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w3</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>several%5:00:00:some(a):00</td>\n",
       "      <td>person.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w4</td>\n",
       "      <td>a period of time containing 365 (or 366) days</td>\n",
       "      <td>True</td>\n",
       "      <td>year%1:28:01::</td>\n",
       "      <td>year.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w5</td>\n",
       "      <td>in the historical present; at this point in th...</td>\n",
       "      <td>True</td>\n",
       "      <td>now%4:02:05::</td>\n",
       "      <td>now.r.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w6</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>the</td>\n",
       "      <td>now.r.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w7</td>\n",
       "      <td>a passenger train that is ridden primarily by ...</td>\n",
       "      <td>True</td>\n",
       "      <td>commuter%1:06:00::</td>\n",
       "      <td>commuter.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w8</td>\n",
       "      <td>line that is the commercial organization respo...</td>\n",
       "      <td>True</td>\n",
       "      <td>railroad%1:06:00::</td>\n",
       "      <td>railway.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w9</td>\n",
       "      <td>devote (part of) one's life or efforts to, as ...</td>\n",
       "      <td>True</td>\n",
       "      <td>serve%2:41:02::</td>\n",
       "      <td>serve.v.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w10</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>our</td>\n",
       "      <td>serve.v.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w11</td>\n",
       "      <td>above average in size or number or quantity or...</td>\n",
       "      <td>True</td>\n",
       "      <td>large%3:00:00::</td>\n",
       "      <td>large.a.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w12</td>\n",
       "      <td>relating to or characteristic of a metropolis</td>\n",
       "      <td>True</td>\n",
       "      <td>metropolitan%3:01:00::</td>\n",
       "      <td>metropolitan.a.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w13</td>\n",
       "      <td>a particular geographical region of indefinite...</td>\n",
       "      <td>True</td>\n",
       "      <td>area%1:15:01::</td>\n",
       "      <td>area.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w14</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>have</td>\n",
       "      <td>area.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w15</td>\n",
       "      <td>establish after a calculation, investigation, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>find%2:32:00::</td>\n",
       "      <td>determine.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w16</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>it</td>\n",
       "      <td>determine.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w17</td>\n",
       "      <td>advancing in amount or intensity</td>\n",
       "      <td>True</td>\n",
       "      <td>increasingly%4:02:00::</td>\n",
       "      <td>increasingly.r.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w18</td>\n",
       "      <td>not easy; requiring great physical or mental e...</td>\n",
       "      <td>True</td>\n",
       "      <td>difficult%3:00:00::</td>\n",
       "      <td>difficult.a.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w19</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>to</td>\n",
       "      <td>difficult.a.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w20</td>\n",
       "      <td>give something useful or necessary to</td>\n",
       "      <td>True</td>\n",
       "      <td>render%2:40:02::</td>\n",
       "      <td>supply.v.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              file  \\\n",
       "0   ../semcor3.0/brown2/br-h13.naf   \n",
       "1   ../semcor3.0/brown2/br-h13.naf   \n",
       "2   ../semcor3.0/brown2/br-h13.naf   \n",
       "3   ../semcor3.0/brown2/br-h13.naf   \n",
       "4   ../semcor3.0/brown2/br-h13.naf   \n",
       "5   ../semcor3.0/brown2/br-h13.naf   \n",
       "6   ../semcor3.0/brown2/br-h13.naf   \n",
       "7   ../semcor3.0/brown2/br-h13.naf   \n",
       "8   ../semcor3.0/brown2/br-h13.naf   \n",
       "9   ../semcor3.0/brown2/br-h13.naf   \n",
       "10  ../semcor3.0/brown2/br-h13.naf   \n",
       "11  ../semcor3.0/brown2/br-h13.naf   \n",
       "12  ../semcor3.0/brown2/br-h13.naf   \n",
       "13  ../semcor3.0/brown2/br-h13.naf   \n",
       "14  ../semcor3.0/brown2/br-h13.naf   \n",
       "15  ../semcor3.0/brown2/br-h13.naf   \n",
       "16  ../semcor3.0/brown2/br-h13.naf   \n",
       "17  ../semcor3.0/brown2/br-h13.naf   \n",
       "18  ../semcor3.0/brown2/br-h13.naf   \n",
       "19  ../semcor3.0/brown2/br-h13.naf   \n",
       "\n",
       "                                              context  \\\n",
       "0   Mr._Speaker for several years now the commuter...   \n",
       "1   Mr._Speaker for several years now the commuter...   \n",
       "2   Mr._Speaker for several years now the commuter...   \n",
       "3   Mr._Speaker for several years now the commuter...   \n",
       "4   Mr._Speaker for several years now the commuter...   \n",
       "5   Mr._Speaker for several years now the commuter...   \n",
       "6   Mr._Speaker for several years now the commuter...   \n",
       "7   Mr._Speaker for several years now the commuter...   \n",
       "8   Mr._Speaker for several years now the commuter...   \n",
       "9   Mr._Speaker for several years now the commuter...   \n",
       "10  Mr._Speaker for several years now the commuter...   \n",
       "11  Mr._Speaker for several years now the commuter...   \n",
       "12  Mr._Speaker for several years now the commuter...   \n",
       "13  Mr._Speaker for several years now the commuter...   \n",
       "14  Mr._Speaker for several years now the commuter...   \n",
       "15  Mr._Speaker for several years now the commuter...   \n",
       "16  Mr._Speaker for several years now the commuter...   \n",
       "17  Mr._Speaker for several years now the commuter...   \n",
       "18  Mr._Speaker for several years now the commuter...   \n",
       "19  Mr._Speaker for several years now the commuter...   \n",
       "\n",
       "                                          context_pos target_word  \\\n",
       "0   Mr._Speaker_NNP for_IN several_JJ years_NN now...          w0   \n",
       "1   Mr._Speaker_NNP for_IN several_JJ years_NN now...          w2   \n",
       "2   Mr._Speaker_NNP for_IN several_JJ years_NN now...          w3   \n",
       "3   Mr._Speaker_NNP for_IN several_JJ years_NN now...          w4   \n",
       "4   Mr._Speaker_NNP for_IN several_JJ years_NN now...          w5   \n",
       "5   Mr._Speaker_NNP for_IN several_JJ years_NN now...          w6   \n",
       "6   Mr._Speaker_NNP for_IN several_JJ years_NN now...          w7   \n",
       "7   Mr._Speaker_NNP for_IN several_JJ years_NN now...          w8   \n",
       "8   Mr._Speaker_NNP for_IN several_JJ years_NN now...          w9   \n",
       "9   Mr._Speaker_NNP for_IN several_JJ years_NN now...         w10   \n",
       "10  Mr._Speaker_NNP for_IN several_JJ years_NN now...         w11   \n",
       "11  Mr._Speaker_NNP for_IN several_JJ years_NN now...         w12   \n",
       "12  Mr._Speaker_NNP for_IN several_JJ years_NN now...         w13   \n",
       "13  Mr._Speaker_NNP for_IN several_JJ years_NN now...         w14   \n",
       "14  Mr._Speaker_NNP for_IN several_JJ years_NN now...         w15   \n",
       "15  Mr._Speaker_NNP for_IN several_JJ years_NN now...         w16   \n",
       "16  Mr._Speaker_NNP for_IN several_JJ years_NN now...         w17   \n",
       "17  Mr._Speaker_NNP for_IN several_JJ years_NN now...         w18   \n",
       "18  Mr._Speaker_NNP for_IN several_JJ years_NN now...         w19   \n",
       "19  Mr._Speaker_NNP for_IN several_JJ years_NN now...         w20   \n",
       "\n",
       "                                                gloss  is_proper_gloss  \\\n",
       "0                                       a human being             True   \n",
       "1                                                                False   \n",
       "2                                                                False   \n",
       "3       a period of time containing 365 (or 366) days             True   \n",
       "4   in the historical present; at this point in th...             True   \n",
       "5                                                                False   \n",
       "6   a passenger train that is ridden primarily by ...             True   \n",
       "7   line that is the commercial organization respo...             True   \n",
       "8   devote (part of) one's life or efforts to, as ...             True   \n",
       "9                                                                False   \n",
       "10  above average in size or number or quantity or...             True   \n",
       "11      relating to or characteristic of a metropolis             True   \n",
       "12  a particular geographical region of indefinite...             True   \n",
       "13                                                               False   \n",
       "14  establish after a calculation, investigation, ...             True   \n",
       "15                                                               False   \n",
       "16                   advancing in amount or intensity             True   \n",
       "17  not easy; requiring great physical or mental e...             True   \n",
       "18                                                               False   \n",
       "19              give something useful or necessary to             True   \n",
       "\n",
       "                      wn_index         sense_full  \n",
       "0             person%1:03:00::        person.n.01  \n",
       "1                          for        person.n.01  \n",
       "2   several%5:00:00:some(a):00        person.n.01  \n",
       "3               year%1:28:01::          year.n.01  \n",
       "4                now%4:02:05::           now.r.01  \n",
       "5                          the           now.r.01  \n",
       "6           commuter%1:06:00::      commuter.n.01  \n",
       "7           railroad%1:06:00::       railway.n.01  \n",
       "8              serve%2:41:02::         serve.v.07  \n",
       "9                          our         serve.v.07  \n",
       "10             large%3:00:00::         large.a.01  \n",
       "11      metropolitan%3:01:00::  metropolitan.a.01  \n",
       "12              area%1:15:01::          area.n.01  \n",
       "13                        have          area.n.01  \n",
       "14              find%2:32:00::     determine.v.01  \n",
       "15                          it     determine.v.01  \n",
       "16      increasingly%4:02:00::  increasingly.r.01  \n",
       "17         difficult%3:00:00::     difficult.a.01  \n",
       "18                          to     difficult.a.01  \n",
       "19            render%2:40:02::        supply.v.01  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm \n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def preprocess_semcor_data(dataset):\n",
    "    cnt = 0\n",
    "    # make copy of dataset\n",
    "    data = dataset.copy()\n",
    "    for i, row in tqdm.tqdm(dataset.iterrows(), total=len(dataset)):\n",
    "        context_words = nltk.word_tokenize(row[\"context\"])\n",
    "        context_pos_words = nltk.word_tokenize(row[\"context_pos\"])\n",
    "        target_word_lemma = row[\"wn_index\"].split(\"%\")[0]\n",
    "        synsets = wn.synsets(target_word_lemma)\n",
    "        trg_idx = int(row['target_word'][1:])\n",
    "        \n",
    "        if len(synsets) >0:\n",
    "            target_synset = synsets[0]\n",
    "        else:\n",
    "            target_synset = None\n",
    "       \n",
    "        window_start = max(0, trg_idx - 10)\n",
    "        window_end = min(len(context_words), trg_idx + 10)\n",
    "        context_window = context_words[window_start:trg_idx] + context_words[trg_idx+1:window_end]\n",
    "        context_window_pos = context_pos_words[window_start:trg_idx] + context_pos_words[trg_idx+1:window_end]\n",
    "        # print(len(context_window))\n",
    "        if len(context_window) == 0:\n",
    "            cnt = cnt + 1\n",
    "        data.at[i, 'context'] = ' '.join(context_window)\n",
    "        data.at[i, 'context_pos'] = ' '.join(context_window_pos)\n",
    "        \n",
    "    data =  data[data[\"gloss\"]!=\"\"]\n",
    "    data = data[data[\"context_pos\"]!=\"\"]\n",
    "    data = data[data[\"context\"]!=\"\"]\n",
    "    # dataset = dataset.drop(columns=[\"wn_index\"])\n",
    "    print(\"Number of proper glosses: \", data[\"is_proper_gloss\"].sum())\n",
    "    print(cnt)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [04:36<00:00, 72.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of proper glosses:  8941\n",
      "2406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = preprocess_semcor_data(df[:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataset\n",
    "dataset.to_csv(\"semcor3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>context</th>\n",
       "      <th>context_pos</th>\n",
       "      <th>target_word</th>\n",
       "      <th>gloss</th>\n",
       "      <th>is_proper_gloss</th>\n",
       "      <th>wn_index</th>\n",
       "      <th>sense_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>for several years now the commuter railroads s...</td>\n",
       "      <td>for_IN several_JJ years_NN now_RB the_DT commu...</td>\n",
       "      <td>w0</td>\n",
       "      <td>a human being</td>\n",
       "      <td>True</td>\n",
       "      <td>person%1:03:00::</td>\n",
       "      <td>person.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years the commuter rai...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN the...</td>\n",
       "      <td>w4</td>\n",
       "      <td>a period of time containing 365 (or 366) days</td>\n",
       "      <td>True</td>\n",
       "      <td>year%1:28:01::</td>\n",
       "      <td>year.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now commuter rai...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w5</td>\n",
       "      <td>in the historical present; at this point in th...</td>\n",
       "      <td>True</td>\n",
       "      <td>now%4:02:05::</td>\n",
       "      <td>now.r.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w7</td>\n",
       "      <td>a passenger train that is ridden primarily by ...</td>\n",
       "      <td>True</td>\n",
       "      <td>commuter%1:06:00::</td>\n",
       "      <td>commuter.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w8</td>\n",
       "      <td>line that is the commercial organization respo...</td>\n",
       "      <td>True</td>\n",
       "      <td>railroad%1:06:00::</td>\n",
       "      <td>railway.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>Mr._Speaker for several years now the commuter...</td>\n",
       "      <td>Mr._Speaker_NNP for_IN several_JJ years_NN now...</td>\n",
       "      <td>w9</td>\n",
       "      <td>devote (part of) one's life or efforts to, as ...</td>\n",
       "      <td>True</td>\n",
       "      <td>serve%2:41:02::</td>\n",
       "      <td>serve.v.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>for several years now the commuter railroads s...</td>\n",
       "      <td>for_IN several_JJ years_NN now_RB the_DT commu...</td>\n",
       "      <td>w11</td>\n",
       "      <td>above average in size or number or quantity or...</td>\n",
       "      <td>True</td>\n",
       "      <td>large%3:00:00::</td>\n",
       "      <td>large.a.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>several years now the commuter railroads servi...</td>\n",
       "      <td>several_JJ years_NN now_RB the_DT commuter_NN ...</td>\n",
       "      <td>w12</td>\n",
       "      <td>relating to or characteristic of a metropolis</td>\n",
       "      <td>True</td>\n",
       "      <td>metropolitan%3:01:00::</td>\n",
       "      <td>metropolitan.a.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>years now the commuter railroads serving our l...</td>\n",
       "      <td>years_NN now_RB the_DT commuter_NN railroads_N...</td>\n",
       "      <td>w13</td>\n",
       "      <td>a particular geographical region of indefinite...</td>\n",
       "      <td>True</td>\n",
       "      <td>area%1:15:01::</td>\n",
       "      <td>area.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>the commuter railroads serving our large metro...</td>\n",
       "      <td>the_DT commuter_NN railroads_NN serving_VB our...</td>\n",
       "      <td>w15</td>\n",
       "      <td>establish after a calculation, investigation, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>find%2:32:00::</td>\n",
       "      <td>determine.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>railroads serving our large metropolitan areas...</td>\n",
       "      <td>railroads_NN serving_VB our_PRP $ large_JJ met...</td>\n",
       "      <td>w17</td>\n",
       "      <td>advancing in amount or intensity</td>\n",
       "      <td>True</td>\n",
       "      <td>increasingly%4:02:00::</td>\n",
       "      <td>increasingly.r.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>serving our large metropolitan areas have foun...</td>\n",
       "      <td>serving_VB our_PRP $ large_JJ metropolitan_JJ ...</td>\n",
       "      <td>w18</td>\n",
       "      <td>not easy; requiring great physical or mental e...</td>\n",
       "      <td>True</td>\n",
       "      <td>difficult%3:00:00::</td>\n",
       "      <td>difficult.a.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>large metropolitan areas have found it increas...</td>\n",
       "      <td>$ large_JJ metropolitan_JJ areas_NN have_VB fo...</td>\n",
       "      <td>w20</td>\n",
       "      <td>give something useful or necessary to</td>\n",
       "      <td>True</td>\n",
       "      <td>render%2:40:02::</td>\n",
       "      <td>supply.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>areas have found it increasingly difficult to ...</td>\n",
       "      <td>metropolitan_JJ areas_NN have_VB found_VB it_P...</td>\n",
       "      <td>w22</td>\n",
       "      <td>a category of things distinguished by some com...</td>\n",
       "      <td>True</td>\n",
       "      <td>kind%1:09:00::</td>\n",
       "      <td>kind.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>found it increasingly difficult to render the ...</td>\n",
       "      <td>have_VB found_VB it_PRP increasingly_RB diffic...</td>\n",
       "      <td>w24</td>\n",
       "      <td>work done by one person or group that benefits...</td>\n",
       "      <td>True</td>\n",
       "      <td>service%1:04:08::</td>\n",
       "      <td>service.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>difficult to render the kind of service our ex...</td>\n",
       "      <td>increasingly_RB difficult_JJ to_TO render_VB t...</td>\n",
       "      <td>w27</td>\n",
       "      <td>the people who inhabit a territory or state</td>\n",
       "      <td>True</td>\n",
       "      <td>population%1:14:00::</td>\n",
       "      <td>population.n.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>to render the kind of service our expanding po...</td>\n",
       "      <td>difficult_JJ to_TO render_VB the_DT kind_NN of...</td>\n",
       "      <td>w28</td>\n",
       "      <td>feel or have a desire for; want strongly</td>\n",
       "      <td>True</td>\n",
       "      <td>want%2:37:00::</td>\n",
       "      <td>desire.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>kind of service our expanding population wants...</td>\n",
       "      <td>the_DT kind_NN of_RB service_NN our_PRP $ expa...</td>\n",
       "      <td>w31</td>\n",
       "      <td>qualified for by right according to law</td>\n",
       "      <td>True</td>\n",
       "      <td>entitled%5:00:00:eligible:00</td>\n",
       "      <td>entitled.s.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>service our expanding population wants and is ...</td>\n",
       "      <td>of_RB service_NN our_PRP $ expanding_JJ popula...</td>\n",
       "      <td>w33</td>\n",
       "      <td>get something; come into possession of</td>\n",
       "      <td>True</td>\n",
       "      <td>have%2:40:03::</td>\n",
       "      <td>receive.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>../semcor3.0/brown2/br-h13.naf</td>\n",
       "      <td>population wants and is entitled to have The c...</td>\n",
       "      <td>$ expanding_JJ population_NN wants_VB and_CC i...</td>\n",
       "      <td>w36</td>\n",
       "      <td>events that provide the generative force that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>cause%1:11:00::</td>\n",
       "      <td>cause.n.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              file  \\\n",
       "0   ../semcor3.0/brown2/br-h13.naf   \n",
       "3   ../semcor3.0/brown2/br-h13.naf   \n",
       "4   ../semcor3.0/brown2/br-h13.naf   \n",
       "6   ../semcor3.0/brown2/br-h13.naf   \n",
       "7   ../semcor3.0/brown2/br-h13.naf   \n",
       "8   ../semcor3.0/brown2/br-h13.naf   \n",
       "10  ../semcor3.0/brown2/br-h13.naf   \n",
       "11  ../semcor3.0/brown2/br-h13.naf   \n",
       "12  ../semcor3.0/brown2/br-h13.naf   \n",
       "14  ../semcor3.0/brown2/br-h13.naf   \n",
       "16  ../semcor3.0/brown2/br-h13.naf   \n",
       "17  ../semcor3.0/brown2/br-h13.naf   \n",
       "19  ../semcor3.0/brown2/br-h13.naf   \n",
       "21  ../semcor3.0/brown2/br-h13.naf   \n",
       "23  ../semcor3.0/brown2/br-h13.naf   \n",
       "26  ../semcor3.0/brown2/br-h13.naf   \n",
       "27  ../semcor3.0/brown2/br-h13.naf   \n",
       "30  ../semcor3.0/brown2/br-h13.naf   \n",
       "32  ../semcor3.0/brown2/br-h13.naf   \n",
       "34  ../semcor3.0/brown2/br-h13.naf   \n",
       "\n",
       "                                              context  \\\n",
       "0   for several years now the commuter railroads s...   \n",
       "3   Mr._Speaker for several years the commuter rai...   \n",
       "4   Mr._Speaker for several years now commuter rai...   \n",
       "6   Mr._Speaker for several years now the commuter...   \n",
       "7   Mr._Speaker for several years now the commuter...   \n",
       "8   Mr._Speaker for several years now the commuter...   \n",
       "10  for several years now the commuter railroads s...   \n",
       "11  several years now the commuter railroads servi...   \n",
       "12  years now the commuter railroads serving our l...   \n",
       "14  the commuter railroads serving our large metro...   \n",
       "16  railroads serving our large metropolitan areas...   \n",
       "17  serving our large metropolitan areas have foun...   \n",
       "19  large metropolitan areas have found it increas...   \n",
       "21  areas have found it increasingly difficult to ...   \n",
       "23  found it increasingly difficult to render the ...   \n",
       "26  difficult to render the kind of service our ex...   \n",
       "27  to render the kind of service our expanding po...   \n",
       "30  kind of service our expanding population wants...   \n",
       "32  service our expanding population wants and is ...   \n",
       "34  population wants and is entitled to have The c...   \n",
       "\n",
       "                                          context_pos target_word  \\\n",
       "0   for_IN several_JJ years_NN now_RB the_DT commu...          w0   \n",
       "3   Mr._Speaker_NNP for_IN several_JJ years_NN the...          w4   \n",
       "4   Mr._Speaker_NNP for_IN several_JJ years_NN now...          w5   \n",
       "6   Mr._Speaker_NNP for_IN several_JJ years_NN now...          w7   \n",
       "7   Mr._Speaker_NNP for_IN several_JJ years_NN now...          w8   \n",
       "8   Mr._Speaker_NNP for_IN several_JJ years_NN now...          w9   \n",
       "10  for_IN several_JJ years_NN now_RB the_DT commu...         w11   \n",
       "11  several_JJ years_NN now_RB the_DT commuter_NN ...         w12   \n",
       "12  years_NN now_RB the_DT commuter_NN railroads_N...         w13   \n",
       "14  the_DT commuter_NN railroads_NN serving_VB our...         w15   \n",
       "16  railroads_NN serving_VB our_PRP $ large_JJ met...         w17   \n",
       "17  serving_VB our_PRP $ large_JJ metropolitan_JJ ...         w18   \n",
       "19  $ large_JJ metropolitan_JJ areas_NN have_VB fo...         w20   \n",
       "21  metropolitan_JJ areas_NN have_VB found_VB it_P...         w22   \n",
       "23  have_VB found_VB it_PRP increasingly_RB diffic...         w24   \n",
       "26  increasingly_RB difficult_JJ to_TO render_VB t...         w27   \n",
       "27  difficult_JJ to_TO render_VB the_DT kind_NN of...         w28   \n",
       "30  the_DT kind_NN of_RB service_NN our_PRP $ expa...         w31   \n",
       "32  of_RB service_NN our_PRP $ expanding_JJ popula...         w33   \n",
       "34  $ expanding_JJ population_NN wants_VB and_CC i...         w36   \n",
       "\n",
       "                                                gloss  is_proper_gloss  \\\n",
       "0                                       a human being             True   \n",
       "3       a period of time containing 365 (or 366) days             True   \n",
       "4   in the historical present; at this point in th...             True   \n",
       "6   a passenger train that is ridden primarily by ...             True   \n",
       "7   line that is the commercial organization respo...             True   \n",
       "8   devote (part of) one's life or efforts to, as ...             True   \n",
       "10  above average in size or number or quantity or...             True   \n",
       "11      relating to or characteristic of a metropolis             True   \n",
       "12  a particular geographical region of indefinite...             True   \n",
       "14  establish after a calculation, investigation, ...             True   \n",
       "16                   advancing in amount or intensity             True   \n",
       "17  not easy; requiring great physical or mental e...             True   \n",
       "19              give something useful or necessary to             True   \n",
       "21  a category of things distinguished by some com...             True   \n",
       "23  work done by one person or group that benefits...             True   \n",
       "26        the people who inhabit a territory or state             True   \n",
       "27           feel or have a desire for; want strongly             True   \n",
       "30            qualified for by right according to law             True   \n",
       "32             get something; come into possession of             True   \n",
       "34  events that provide the generative force that ...             True   \n",
       "\n",
       "                        wn_index         sense_full  \n",
       "0               person%1:03:00::        person.n.01  \n",
       "3                 year%1:28:01::          year.n.01  \n",
       "4                  now%4:02:05::           now.r.01  \n",
       "6             commuter%1:06:00::      commuter.n.01  \n",
       "7             railroad%1:06:00::       railway.n.01  \n",
       "8                serve%2:41:02::         serve.v.07  \n",
       "10               large%3:00:00::         large.a.01  \n",
       "11        metropolitan%3:01:00::  metropolitan.a.01  \n",
       "12                area%1:15:01::          area.n.01  \n",
       "14                find%2:32:00::     determine.v.01  \n",
       "16        increasingly%4:02:00::  increasingly.r.01  \n",
       "17           difficult%3:00:00::     difficult.a.01  \n",
       "19              render%2:40:02::        supply.v.01  \n",
       "21                kind%1:09:00::          kind.n.01  \n",
       "23             service%1:04:08::       service.n.01  \n",
       "26          population%1:14:00::    population.n.01  \n",
       "27                want%2:37:00::        desire.v.01  \n",
       "30  entitled%5:00:00:eligible:00      entitled.s.01  \n",
       "32                have%2:40:03::       receive.v.01  \n",
       "34               cause%1:11:00::         cause.n.01  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 12.8kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 570/570 [00:00<00:00, 310kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 3.60MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 4.30MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 440M/440M [01:13<00:00, 6.00MB/s] \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/abhishek/miniconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "max_len = 20\n",
    "\n",
    "\n",
    "def create_embeddings(sentences, tokenizer, model, max_length):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # Tokenize each sentence and add special tokens for BERT\n",
    "    for sentence in sentences:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Convert the tokenized input into torch tensors\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "\n",
    "    # Feed the input to BERT and get the embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_masks)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "embeddings = create_embeddings(\n",
    "    X_train['context'], tokenizer, model, max_len)\n",
    "np.save('knn_bert2.npy', embeddings)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7152, 768)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = create_embeddings(\n",
    "    X_test['context'], tokenizer, model, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "XTrain = pd.DataFrame(columns=['file', 'context', 'target_word', 'gloss', 'is_proper_gloss','wn_index'])\n",
    "XTest = pd.DataFrame(columns=['file', 'context', 'target_word', 'gloss', 'is_proper_gloss','wn_index'])\n",
    "\n",
    "XTrain = pd.concat([XTrain, X_train], ignore_index=True)\n",
    "XTest = pd.concat([XTest, X_test], ignore_index=True)\n",
    "\n",
    "XTrain.head(10)\n",
    "\n",
    "cosine_similarities = []\n",
    "zero_cos = 0\n",
    "\n",
    "for i,test_embedding in enumerate(test_embeddings):\n",
    "    test_target_word = XTest.iloc[i]['wn_index']\n",
    "    train_rows = XTrain[XTrain['wn_index'] == test_target_word ]\n",
    "    for j,train_row in train_rows.iterrows():\n",
    "        train_embedding = embeddings[j]\n",
    "        similarity = np.dot(test_embedding, train_embedding) / (np.linalg.norm(test_embedding) * np.linalg.norm(train_embedding))\n",
    "        cosine_similarities.append(similarity)\n",
    "    if len(cosine_similarities) == 0:\n",
    "        zero_cos += 1\n",
    "    if len(cosine_similarities) > 0 :\n",
    "        # without using loc\n",
    "        XTest.at[i, 'cosine_similarity'] = max(cosine_similarities)\n",
    "    else:\n",
    "        # X_test.loc[X_test.index[i], 'cosine_similarity'] = -1\n",
    "        XTest.at[i, 'cosine_similarity'] = -1\n",
    "    cosine_similarities = []\n",
    "\n",
    "\n",
    "XTest['correct'] = XTest.apply(lambda row: row['gloss'] in XTrain[XTrain['wn_index']\n",
    "                                 == row['wn_index']].head(10)['gloss'].tolist(), axis=1)\n",
    "\n",
    "# # print the top-5 glosses of X_train for every X_test row \n",
    "X_test['top_5_glosses'] = X_test.apply(lambda row: X_train[X_train['wn_index'] == row['wn_index']].head(5)['gloss'].tolist(), axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  67.13247624371157\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>context</th>\n",
       "      <th>context_pos</th>\n",
       "      <th>target_word</th>\n",
       "      <th>gloss</th>\n",
       "      <th>is_proper_gloss</th>\n",
       "      <th>wn_index</th>\n",
       "      <th>sense_full</th>\n",
       "      <th>top_5_glosses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13331</th>\n",
       "      <td>../semcor3.0/brown2/br-n15.naf</td>\n",
       "      <td>which was up and which was down He held the wh...</td>\n",
       "      <td>His_PRP $ speed_NN was_VBD dropping_VB rapidly...</td>\n",
       "      <td>w1934</td>\n",
       "      <td>done or occurring in a brief period of time</td>\n",
       "      <td>True</td>\n",
       "      <td>rapid%5:00:00:fast:01</td>\n",
       "      <td>rapid.s.01</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9843</th>\n",
       "      <td>../semcor3.0/brown2/br-h11.naf</td>\n",
       "      <td>testing of new apparatus to measure other prop...</td>\n",
       "      <td>testing_NN of_IN new_JJ apparatus_NN to_TO mea...</td>\n",
       "      <td>w96</td>\n",
       "      <td>determine the measurements of something or som...</td>\n",
       "      <td>True</td>\n",
       "      <td>measure%2:31:00::</td>\n",
       "      <td>measure.v.01</td>\n",
       "      <td>[determine the measurements of something or so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8804</th>\n",
       "      <td>../semcor3.0/brown2/br-g12.naf</td>\n",
       "      <td>not attempt to answer I asked about the battle...</td>\n",
       "      <td>all_DT is_VB settled_JJ But_CC it_PRP is_VB di...</td>\n",
       "      <td>w1172</td>\n",
       "      <td>capable of being foretold</td>\n",
       "      <td>True</td>\n",
       "      <td>predictable%3:00:00::</td>\n",
       "      <td>predictable.a.01</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19525</th>\n",
       "      <td>../semcor3.0/brown2/br-g16.naf</td>\n",
       "      <td>artists who have documented the disintegrative...</td>\n",
       "      <td>generations_NN of_IN artists_NN who_WP have_VB...</td>\n",
       "      <td>w84</td>\n",
       "      <td>record in detail</td>\n",
       "      <td>True</td>\n",
       "      <td>document%2:32:00::</td>\n",
       "      <td>document.v.01</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12028</th>\n",
       "      <td>../semcor3.0/brown2/br-n15.naf</td>\n",
       "      <td>watching for every speck in the sky Greg rumbl...</td>\n",
       "      <td>combat_mission_NN Yet_RB long_RB before_IN the...</td>\n",
       "      <td>w424</td>\n",
       "      <td>a human being</td>\n",
       "      <td>True</td>\n",
       "      <td>person%1:03:00::</td>\n",
       "      <td>person.n.01</td>\n",
       "      <td>[a human being, a human being, a human being, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>../semcor3.0/brown2/br-e28.naf</td>\n",
       "      <td>important If you have a higher quality product...</td>\n",
       "      <td>can_MD you_PRP cash_in_on_VB this_DT fast-grow...</td>\n",
       "      <td>w888</td>\n",
       "      <td>a business relation in which two parties compe...</td>\n",
       "      <td>True</td>\n",
       "      <td>competition%1:24:01::</td>\n",
       "      <td>competition.n.01</td>\n",
       "      <td>[a business relation in which two parties comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13323</th>\n",
       "      <td>../semcor3.0/brown2/br-n15.naf</td>\n",
       "      <td>back He fought the panic of vertigo He had no ...</td>\n",
       "      <td>him_PRP near_IN the_DT overcast_NN almost_RB i...</td>\n",
       "      <td>w1923</td>\n",
       "      <td>rise dramatically</td>\n",
       "      <td>True</td>\n",
       "      <td>shoot_up%2:30:00::</td>\n",
       "      <td>shoot_up.v.01</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14189</th>\n",
       "      <td>../semcor3.0/brown2/br-l16.naf</td>\n",
       "      <td>over the laundry_truck One more muddleheaded p...</td>\n",
       "      <td>if_IN he_PRP would_MD make_VB a_DT fool_NN of_...</td>\n",
       "      <td>w734</td>\n",
       "      <td>make it possible through a specific action or ...</td>\n",
       "      <td>True</td>\n",
       "      <td>let%2:41:00::</td>\n",
       "      <td>let.v.01</td>\n",
       "      <td>[make it possible through a specific action or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15648</th>\n",
       "      <td>../semcor3.0/brown2/br-g17.naf</td>\n",
       "      <td>an automobile ride from Memphis to Hattiesburg...</td>\n",
       "      <td>an_DT automobile_NN ride_NN from_IN Memphis_NN...</td>\n",
       "      <td>w56</td>\n",
       "      <td>a motor vehicle with four wheels; usually prop...</td>\n",
       "      <td>True</td>\n",
       "      <td>automobile%1:06:00::</td>\n",
       "      <td>car.n.01</td>\n",
       "      <td>[a motor vehicle with four wheels; usually pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14253</th>\n",
       "      <td>../semcor3.0/brown2/br-l16.naf</td>\n",
       "      <td>Griffith 's carrying his message and he had no...</td>\n",
       "      <td>had_VBD not_RB stayed_on_VB the_DT front_JJ st...</td>\n",
       "      <td>w822</td>\n",
       "      <td>subjected to great tension; stretched tight</td>\n",
       "      <td>True</td>\n",
       "      <td>taut%5:00:00:tense:03</td>\n",
       "      <td>taut.s.02</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file  \\\n",
       "13331  ../semcor3.0/brown2/br-n15.naf   \n",
       "9843   ../semcor3.0/brown2/br-h11.naf   \n",
       "8804   ../semcor3.0/brown2/br-g12.naf   \n",
       "19525  ../semcor3.0/brown2/br-g16.naf   \n",
       "12028  ../semcor3.0/brown2/br-n15.naf   \n",
       "2716   ../semcor3.0/brown2/br-e28.naf   \n",
       "13323  ../semcor3.0/brown2/br-n15.naf   \n",
       "14189  ../semcor3.0/brown2/br-l16.naf   \n",
       "15648  ../semcor3.0/brown2/br-g17.naf   \n",
       "14253  ../semcor3.0/brown2/br-l16.naf   \n",
       "\n",
       "                                                 context  \\\n",
       "13331  which was up and which was down He held the wh...   \n",
       "9843   testing of new apparatus to measure other prop...   \n",
       "8804   not attempt to answer I asked about the battle...   \n",
       "19525  artists who have documented the disintegrative...   \n",
       "12028  watching for every speck in the sky Greg rumbl...   \n",
       "2716   important If you have a higher quality product...   \n",
       "13323  back He fought the panic of vertigo He had no ...   \n",
       "14189  over the laundry_truck One more muddleheaded p...   \n",
       "15648  an automobile ride from Memphis to Hattiesburg...   \n",
       "14253  Griffith 's carrying his message and he had no...   \n",
       "\n",
       "                                             context_pos target_word  \\\n",
       "13331  His_PRP $ speed_NN was_VBD dropping_VB rapidly...       w1934   \n",
       "9843   testing_NN of_IN new_JJ apparatus_NN to_TO mea...         w96   \n",
       "8804   all_DT is_VB settled_JJ But_CC it_PRP is_VB di...       w1172   \n",
       "19525  generations_NN of_IN artists_NN who_WP have_VB...         w84   \n",
       "12028  combat_mission_NN Yet_RB long_RB before_IN the...        w424   \n",
       "2716   can_MD you_PRP cash_in_on_VB this_DT fast-grow...        w888   \n",
       "13323  him_PRP near_IN the_DT overcast_NN almost_RB i...       w1923   \n",
       "14189  if_IN he_PRP would_MD make_VB a_DT fool_NN of_...        w734   \n",
       "15648  an_DT automobile_NN ride_NN from_IN Memphis_NN...         w56   \n",
       "14253  had_VBD not_RB stayed_on_VB the_DT front_JJ st...        w822   \n",
       "\n",
       "                                                   gloss  is_proper_gloss  \\\n",
       "13331        done or occurring in a brief period of time             True   \n",
       "9843   determine the measurements of something or som...             True   \n",
       "8804                           capable of being foretold             True   \n",
       "19525                                   record in detail             True   \n",
       "12028                                      a human being             True   \n",
       "2716   a business relation in which two parties compe...             True   \n",
       "13323                                  rise dramatically             True   \n",
       "14189  make it possible through a specific action or ...             True   \n",
       "15648  a motor vehicle with four wheels; usually prop...             True   \n",
       "14253        subjected to great tension; stretched tight             True   \n",
       "\n",
       "                    wn_index        sense_full  \\\n",
       "13331  rapid%5:00:00:fast:01        rapid.s.01   \n",
       "9843       measure%2:31:00::      measure.v.01   \n",
       "8804   predictable%3:00:00::  predictable.a.01   \n",
       "19525     document%2:32:00::     document.v.01   \n",
       "12028       person%1:03:00::       person.n.01   \n",
       "2716   competition%1:24:01::  competition.n.01   \n",
       "13323     shoot_up%2:30:00::     shoot_up.v.01   \n",
       "14189          let%2:41:00::          let.v.01   \n",
       "15648   automobile%1:06:00::          car.n.01   \n",
       "14253  taut%5:00:00:tense:03         taut.s.02   \n",
       "\n",
       "                                           top_5_glosses  \n",
       "13331                                                 []  \n",
       "9843   [determine the measurements of something or so...  \n",
       "8804                                                  []  \n",
       "19525                                                 []  \n",
       "12028  [a human being, a human being, a human being, ...  \n",
       "2716   [a business relation in which two parties comp...  \n",
       "13323                                                 []  \n",
       "14189  [make it possible through a specific action or...  \n",
       "15648  [a motor vehicle with four wheels; usually pro...  \n",
       "14253                                                 []  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracy = XTest['correct'].sum() / len(XTest)\n",
    "print(\"Accuracy: \", accuracy*100)\n",
    "X_test.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8941\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "data = pd.read_csv(\"semcor3.csv\")\n",
    "print(len(data))\n",
    "test_data = data[:500]\n",
    "train_data = data[500:]\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "# Compute BERT embeddings for each sentence and target word\n",
    "embeddings = []\n",
    "for i, row in data.iterrows():\n",
    "    context = row['context']\n",
    "    context_pos = row['context_pos']\n",
    "    # print(len(context_pos.split()))\n",
    "    target_word = row['sense_full']\n",
    "    gloss = row['gloss']\n",
    "    tokens = tokenizer.encode(context, target_word, add_special_tokens=False)\n",
    "    pos_tag_tokens = tokenizer.encode(context, add_special_tokens=False)\n",
    "    # shuffle the pos_tag_tokens list\n",
    "    np.random.shuffle(pos_tag_tokens)\n",
    "    gloss_tokens = tokenizer.encode(gloss, add_special_tokens=False)\n",
    "    tokens = tokens + [tokenizer.sep_token_id] + gloss_tokens \n",
    "\n",
    "    input_ids = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "    pos_tag_ids = torch.tensor(pos_tag_tokens).unsqueeze(0).to(device)\n",
    "    # Compute BERT embeddings\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)\n",
    "        context_embedding = output[0][0][1:-1].mean(dim=0).cpu()\n",
    "        pos_embedding = model(pos_tag_ids)[0][0][1:-1].mean(dim=0).cpu()\n",
    "\n",
    "    embedding = torch.cat([context_embedding, pos_embedding], dim=0).cpu().numpy()\n",
    "    embeddings.append(embedding) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the embeddings\n",
    "# embedding = embeddings.cpu().numpy()\n",
    "np.save('naive_bert_embeddings.npy', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train = np.array(embeddings)\n",
    "y_train = data['wn_index'].values\n",
    "# print(x_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = embeddings[:500]\n",
    "x_test = np.array(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_probs = {}\n",
    "likelihoods = {}\n",
    "y_test = test_data['wn_index'].values\n",
    "\n",
    "for sense in set(y_train):\n",
    "    sense_count = sum(y_train == sense)\n",
    "    # print(sense,sense_count)\n",
    "    prior_probs[sense] = sense_count / len(y_train)   \n",
    "    sense_embeddings = [x_train[i] for i in range(len(x_train)) if y_train[i] == sense]\n",
    "    likelihoods[sense] = np.mean(sense_embeddings, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(0,len(y_test)):\n",
    "    max_prob = 0\n",
    "    max_sense = None\n",
    "    for sense in set(y_train):\n",
    "        log_prob = prior_probs[sense]\n",
    "        # print(log_prob)\n",
    "        for j in range(len(x_test[i])):\n",
    "            log_prob = log_prob + x_test[i][j] * likelihoods[sense][j]\n",
    "        if log_prob > max_prob:\n",
    "            max_prob = log_prob\n",
    "            max_sense = sense\n",
    "    y_pred.append(max_sense)\n",
    "\n",
    "accuracy = sum(y_pred[i] == y_test.tolist()[i]\n",
    "               for i in range(len(y_test)))/len(y_test)  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy with context + poss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.2\n"
     ]
    }
   ],
   "source": [
    "print(accuracy*100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy with context as only feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad0a8d25012454fce516fd02556d13b58ba350644df31d02f07d47f8074eb7a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
