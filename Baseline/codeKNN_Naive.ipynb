{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/abhishek/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "\n",
    "def read_semcor_data(path):\n",
    "    \"\"\"\n",
    "    Read SemCor data from a directory and return a pandas DataFrame\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for subdir, _, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('.naf'):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                tree = ET.parse(file_path)\n",
    "                root = tree.getroot()\n",
    "                context_pos_sent = []\n",
    "                context_sent = []\n",
    "                cont_dict = {}\n",
    "                for text in root.findall('./text'):\n",
    "                    for wf in text.findall('wf'):\n",
    "                        key = wf.attrib['id'] + \"%\" + file_path\n",
    "                        cont_dict[key] = wf.text\n",
    "\n",
    "                # add the pos tag to the context\n",
    "                for term in root.findall('./terms/term'):\n",
    "                    target_word = term.find(\n",
    "                        \"./span/target\").attrib['id'] + \"%\" + file_path\n",
    "                    pos = term.attrib['pos']\n",
    "                    context_pos_sent.append(cont_dict[target_word] + '_' + pos)\n",
    "                    context_sent.append(cont_dict[target_word])\n",
    "                context_pos = ' '.join(context_pos_sent)\n",
    "                context = ' '.join(context_sent)\n",
    "\n",
    "                for term in root.findall('./terms/term'):\n",
    "                    sense_number = term.find(\n",
    "                        \"./externalReferences/externalRef[@reftype='sense_number']\")\n",
    "                    lemma = term.attrib['lemma']\n",
    "                    lexical_key = term.find(\n",
    "                        \"./externalReferences/externalRef[@reftype='lexical_key']\")\n",
    "                    target_word = term.find(\"./span/target\").attrib['id']\n",
    "                    gloss = \"\"\n",
    "                    wn_index = lemma\n",
    "                    is_proper_gloss = False\n",
    "                    synset_full = \"\"\n",
    "                    if lexical_key is not None:\n",
    "                        lexical_key = lexical_key.attrib['reference']\n",
    "                    if sense_number is not None and sense_number.attrib['reference'] != \"0\":\n",
    "                        wn_index = lemma + \"%\" + lexical_key\n",
    "\n",
    "                        synset_val = term.find(\n",
    "                            \"./externalReferences/externalRef[@reftype='synset']\")\n",
    "\n",
    "                        if synset_val is not None:\n",
    "                            synset_val = synset_val.attrib['reference']\n",
    "                            synset_obj = wn.synset_from_pos_and_offset(\n",
    "                                synset_val[-1], int(synset_val[6:-2]))\n",
    "                            synset_full = synset_obj.name()\n",
    "                            # print(synset_full)\n",
    "                            # synset_name = synset_full[:synset_full.index('.')]\n",
    "                            flg = 0\n",
    "                            for sense in wn.synsets(lemma):\n",
    "                                if sense.name() == synset_full:\n",
    "                                    gloss = sense.definition()\n",
    "                                    flg = 1\n",
    "                                    break\n",
    "                            if flg == 1:\n",
    "                                is_proper_gloss = True\n",
    "\n",
    "                    data.append({\n",
    "                        \"file\": file_path,\n",
    "                        \"context\": context,\n",
    "                        \"context_pos\": context_pos,\n",
    "                        \"target_word\": target_word,\n",
    "                        \"gloss\": gloss,\n",
    "                        \"is_proper_gloss\": is_proper_gloss,\n",
    "                        \"wn_index\": wn_index,\n",
    "                        \"sense_full\": synset_full,\n",
    "                    })\n",
    "\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = \"./semcor3.0/brownv\"\n",
    "df = read_semcor_data(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>context</th>\n",
       "      <th>context_pos</th>\n",
       "      <th>target_word</th>\n",
       "      <th>gloss</th>\n",
       "      <th>is_proper_gloss</th>\n",
       "      <th>wn_index</th>\n",
       "      <th>sense_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w0</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w1</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>baltimore</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w2</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>and</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w3</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>ohio_railroad</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w4</td>\n",
       "      <td>make known; make an announcement</td>\n",
       "      <td>True</td>\n",
       "      <td>announce%2:32:00::</td>\n",
       "      <td>announce.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w5</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>yesterday</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w6</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>it</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w7</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>would</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w8</td>\n",
       "      <td>cut down on; make a reduction in</td>\n",
       "      <td>True</td>\n",
       "      <td>reduce%2:30:00::</td>\n",
       "      <td>reduce.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w9</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w10</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>total</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w11</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>amount</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w12</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>of</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w13</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>its</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w14</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>payroll</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w15</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>by</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w16</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w17</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>per_cent</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w18</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>through</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w19</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>salary</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file  \\\n",
       "0   ./semcor3.0/brownv/br-a19.naf   \n",
       "1   ./semcor3.0/brownv/br-a19.naf   \n",
       "2   ./semcor3.0/brownv/br-a19.naf   \n",
       "3   ./semcor3.0/brownv/br-a19.naf   \n",
       "4   ./semcor3.0/brownv/br-a19.naf   \n",
       "5   ./semcor3.0/brownv/br-a19.naf   \n",
       "6   ./semcor3.0/brownv/br-a19.naf   \n",
       "7   ./semcor3.0/brownv/br-a19.naf   \n",
       "8   ./semcor3.0/brownv/br-a19.naf   \n",
       "9   ./semcor3.0/brownv/br-a19.naf   \n",
       "10  ./semcor3.0/brownv/br-a19.naf   \n",
       "11  ./semcor3.0/brownv/br-a19.naf   \n",
       "12  ./semcor3.0/brownv/br-a19.naf   \n",
       "13  ./semcor3.0/brownv/br-a19.naf   \n",
       "14  ./semcor3.0/brownv/br-a19.naf   \n",
       "15  ./semcor3.0/brownv/br-a19.naf   \n",
       "16  ./semcor3.0/brownv/br-a19.naf   \n",
       "17  ./semcor3.0/brownv/br-a19.naf   \n",
       "18  ./semcor3.0/brownv/br-a19.naf   \n",
       "19  ./semcor3.0/brownv/br-a19.naf   \n",
       "\n",
       "                                              context  \\\n",
       "0   The Baltimore and Ohio_Railroad announced yest...   \n",
       "1   The Baltimore and Ohio_Railroad announced yest...   \n",
       "2   The Baltimore and Ohio_Railroad announced yest...   \n",
       "3   The Baltimore and Ohio_Railroad announced yest...   \n",
       "4   The Baltimore and Ohio_Railroad announced yest...   \n",
       "5   The Baltimore and Ohio_Railroad announced yest...   \n",
       "6   The Baltimore and Ohio_Railroad announced yest...   \n",
       "7   The Baltimore and Ohio_Railroad announced yest...   \n",
       "8   The Baltimore and Ohio_Railroad announced yest...   \n",
       "9   The Baltimore and Ohio_Railroad announced yest...   \n",
       "10  The Baltimore and Ohio_Railroad announced yest...   \n",
       "11  The Baltimore and Ohio_Railroad announced yest...   \n",
       "12  The Baltimore and Ohio_Railroad announced yest...   \n",
       "13  The Baltimore and Ohio_Railroad announced yest...   \n",
       "14  The Baltimore and Ohio_Railroad announced yest...   \n",
       "15  The Baltimore and Ohio_Railroad announced yest...   \n",
       "16  The Baltimore and Ohio_Railroad announced yest...   \n",
       "17  The Baltimore and Ohio_Railroad announced yest...   \n",
       "18  The Baltimore and Ohio_Railroad announced yest...   \n",
       "19  The Baltimore and Ohio_Railroad announced yest...   \n",
       "\n",
       "                                          context_pos target_word  \\\n",
       "0   The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...          w0   \n",
       "1   The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...          w1   \n",
       "2   The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...          w2   \n",
       "3   The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...          w3   \n",
       "4   The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...          w4   \n",
       "5   The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...          w5   \n",
       "6   The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...          w6   \n",
       "7   The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...          w7   \n",
       "8   The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...          w8   \n",
       "9   The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...          w9   \n",
       "10  The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...         w10   \n",
       "11  The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...         w11   \n",
       "12  The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...         w12   \n",
       "13  The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...         w13   \n",
       "14  The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...         w14   \n",
       "15  The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...         w15   \n",
       "16  The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...         w16   \n",
       "17  The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...         w17   \n",
       "18  The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...         w18   \n",
       "19  The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...         w19   \n",
       "\n",
       "                               gloss  is_proper_gloss            wn_index  \\\n",
       "0                                               False                 the   \n",
       "1                                               False           baltimore   \n",
       "2                                               False                 and   \n",
       "3                                               False       ohio_railroad   \n",
       "4   make known; make an announcement             True  announce%2:32:00::   \n",
       "5                                               False           yesterday   \n",
       "6                                               False                  it   \n",
       "7                                               False               would   \n",
       "8   cut down on; make a reduction in             True    reduce%2:30:00::   \n",
       "9                                               False                 the   \n",
       "10                                              False               total   \n",
       "11                                              False              amount   \n",
       "12                                              False                  of   \n",
       "13                                              False                 its   \n",
       "14                                              False             payroll   \n",
       "15                                              False                  by   \n",
       "16                                              False                  10   \n",
       "17                                              False            per_cent   \n",
       "18                                              False             through   \n",
       "19                                              False              salary   \n",
       "\n",
       "       sense_full  \n",
       "0                  \n",
       "1                  \n",
       "2                  \n",
       "3                  \n",
       "4   announce.v.01  \n",
       "5                  \n",
       "6                  \n",
       "7                  \n",
       "8     reduce.v.01  \n",
       "9                  \n",
       "10                 \n",
       "11                 \n",
       "12                 \n",
       "13                 \n",
       "14                 \n",
       "15                 \n",
       "16                 \n",
       "17                 \n",
       "18                 \n",
       "19                 "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm \n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def preprocess_semcor_data(dataset):\n",
    "    cnt = 0\n",
    "    # make copy of dataset\n",
    "    data = dataset.copy()\n",
    "    for i, row in tqdm.tqdm(dataset.iterrows(), total=len(dataset)):\n",
    "        context_words = nltk.word_tokenize(row[\"context\"])\n",
    "        context_pos_words = nltk.word_tokenize(row[\"context_pos\"])\n",
    "        target_word_lemma = row[\"wn_index\"].split(\"%\")[0]\n",
    "        synsets = wn.synsets(target_word_lemma)\n",
    "        trg_idx = int(row['target_word'][1:])\n",
    "        \n",
    "        if len(synsets) >0:\n",
    "            target_synset = synsets[0]\n",
    "        else:\n",
    "            target_synset = None\n",
    "       \n",
    "        window_start = max(0, trg_idx - 10)\n",
    "        window_end = min(len(context_words), trg_idx + 10)\n",
    "        context_window = context_words[window_start:trg_idx] + context_words[trg_idx+1:window_end]\n",
    "        context_window_pos = context_pos_words[window_start:trg_idx] + context_pos_words[trg_idx+1:window_end]\n",
    "        # print(len(context_window))\n",
    "        if len(context_window) == 0:\n",
    "            cnt = cnt + 1\n",
    "        data.at[i, 'context'] = ' '.join(context_window)\n",
    "        data.at[i, 'context_pos'] = ' '.join(context_window_pos)\n",
    "        \n",
    "    data =  data[data[\"gloss\"]!=\"\"]\n",
    "    data = data[data[\"context_pos\"]!=\"\"]\n",
    "    data = data[data[\"context\"]!=\"\"]\n",
    "    # dataset = dataset.drop(columns=[\"wn_index\"])\n",
    "    print(\"Number of proper glosses: \", data[\"is_proper_gloss\"].sum())\n",
    "    print(cnt)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [15:55<00:00, 52.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of proper glosses:  5756\n",
      "6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = preprocess_semcor_data(df[:50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataset\n",
    "dataset.to_csv(\"semcor5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the row if sense_full if empty\n",
    "dataset = dataset[dataset[\"sense_full\"]!=\"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>context</th>\n",
       "      <th>context_pos</th>\n",
       "      <th>target_word</th>\n",
       "      <th>gloss</th>\n",
       "      <th>is_proper_gloss</th>\n",
       "      <th>wn_index</th>\n",
       "      <th>sense_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad yesterday it w...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w4</td>\n",
       "      <td>make known; make an announcement</td>\n",
       "      <td>True</td>\n",
       "      <td>announce%2:32:00::</td>\n",
       "      <td>announce.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>The Baltimore and Ohio_Railroad announced yest...</td>\n",
       "      <td>The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...</td>\n",
       "      <td>w8</td>\n",
       "      <td>cut down on; make a reduction in</td>\n",
       "      <td>True</td>\n",
       "      <td>reduce%2:30:00::</td>\n",
       "      <td>reduce.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>at 12.01 A._M . next Saturday The current mont...</td>\n",
       "      <td>effective_JJ at_IN 12.01_CD A._M._NNP next_JJ ...</td>\n",
       "      <td>w34</td>\n",
       "      <td>add up in number or quantity</td>\n",
       "      <td>True</td>\n",
       "      <td>come%2:42:12::</td>\n",
       "      <td>total.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>15000000 Howard_E._Simpson the railroad 's pre...</td>\n",
       "      <td>15000000_CD Howard_E._Simpson_NNP the_DT railr...</td>\n",
       "      <td>w47</td>\n",
       "      <td>express in words</td>\n",
       "      <td>True</td>\n",
       "      <td>say%2:32:00::</td>\n",
       "      <td>state.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>of heavy goods has necessitated this regrettab...</td>\n",
       "      <td>of_IN heavy_JJ goods_NNS has_VBZ necessitated_...</td>\n",
       "      <td>w69</td>\n",
       "      <td>cause to be a concomitant</td>\n",
       "      <td>True</td>\n",
       "      <td>necessitate%2:42:01::</td>\n",
       "      <td>necessitate.v.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>expenses will affect employees in the thirteen...</td>\n",
       "      <td>expenses_NNS will_MD affect_VB employees_NNS i...</td>\n",
       "      <td>w80</td>\n",
       "      <td>connect closely and often incriminatingly</td>\n",
       "      <td>True</td>\n",
       "      <td>affect%2:42:00::</td>\n",
       "      <td>involve.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>O. operates It will be accomplished in_two_way...</td>\n",
       "      <td>O._NNP operates_VB It_PRP will_MD be_VB accomp...</td>\n",
       "      <td>w91</td>\n",
       "      <td>direct or control; projects, businesses, etc.</td>\n",
       "      <td>True</td>\n",
       "      <td>operate%2:41:00::</td>\n",
       "      <td>operate.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>accomplished in_two_ways A flat reduction of 1...</td>\n",
       "      <td>accomplished_VB in_two_ways_RB A_DT flat_JJ re...</td>\n",
       "      <td>w96</td>\n",
       "      <td>put in effect</td>\n",
       "      <td>True</td>\n",
       "      <td>accomplish%2:36:00::</td>\n",
       "      <td>carry_through.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>There are about 3325 officers and employees in...</td>\n",
       "      <td>There_EX are_VB about_RB 3325_CD officers_NNS ...</td>\n",
       "      <td>w117</td>\n",
       "      <td>be a part or adjunct</td>\n",
       "      <td>True</td>\n",
       "      <td>belong_to%2:42:00::</td>\n",
       "      <td>belong_to.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>officers and employees in_this class Sufficien...</td>\n",
       "      <td>officers_NNS and_CC employees_NNS in_this_RB c...</td>\n",
       "      <td>w121</td>\n",
       "      <td>have an existence, be extant</td>\n",
       "      <td>True</td>\n",
       "      <td>be%2:42:00::</td>\n",
       "      <td>exist.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>individual union_members under contract it mus...</td>\n",
       "      <td>union_members_NN under_IN contract_NN it_PRP m...</td>\n",
       "      <td>w151</td>\n",
       "      <td>cut down on; make a reduction in</td>\n",
       "      <td>True</td>\n",
       "      <td>reduce%2:30:00::</td>\n",
       "      <td>reduce.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>placing some of the men on furlough a B. O. sa...</td>\n",
       "      <td>placing_VB some_DT of_IN the_DT men_NNS on_IN ...</td>\n",
       "      <td>w162</td>\n",
       "      <td>put in effect</td>\n",
       "      <td>True</td>\n",
       "      <td>accomplish%2:36:00::</td>\n",
       "      <td>carry_through.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>on furlough a B. O. spokesman said Those union...</td>\n",
       "      <td>on_IN furlough_NN a_DT B._NNP O._NNP spokesman...</td>\n",
       "      <td>w167</td>\n",
       "      <td>place somebody in a particular situation or lo...</td>\n",
       "      <td>True</td>\n",
       "      <td>place%2:41:01::</td>\n",
       "      <td>place.v.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>therefore will not take a cut in their wages T...</td>\n",
       "      <td>jobs_NNS therefore_RB will_MD not_RB take_VB a...</td>\n",
       "      <td>w180</td>\n",
       "      <td>express in words</td>\n",
       "      <td>True</td>\n",
       "      <td>say%2:32:00::</td>\n",
       "      <td>state.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>a cut in their wages The spokesman said the nu...</td>\n",
       "      <td>take_VB a_DT cut_NN in_IN their_PRP $ wages_NN...</td>\n",
       "      <td>w184</td>\n",
       "      <td>keep in a certain state, position, or activity...</td>\n",
       "      <td>True</td>\n",
       "      <td>keep%2:42:00::</td>\n",
       "      <td>keep.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>number to be furloughed can not be estimated s...</td>\n",
       "      <td>said_VB the_DT number_NN to_TO be_VB furloughe...</td>\n",
       "      <td>w193</td>\n",
       "      <td>accept or undergo, often unwillingly</td>\n",
       "      <td>True</td>\n",
       "      <td>take%2:31:09::</td>\n",
       "      <td>take.v.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>the lay-offs must be carried_out in each area ...</td>\n",
       "      <td>since_IN the_DT lay-offs_NNS must_MD be_VB car...</td>\n",
       "      <td>w202</td>\n",
       "      <td>report or maintain</td>\n",
       "      <td>True</td>\n",
       "      <td>say%2:32:01::</td>\n",
       "      <td>allege.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>in each area depending_on what men are most ne...</td>\n",
       "      <td>carried_out_VB in_IN each_DT area_NN depending...</td>\n",
       "      <td>w207</td>\n",
       "      <td>dismiss, usually for economic reasons</td>\n",
       "      <td>True</td>\n",
       "      <td>furlough%2:41:00::</td>\n",
       "      <td>furlough.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>depending_on what men are most needed on_the_j...</td>\n",
       "      <td>area_NN depending_on_JJ what_WP men_NNS are_VB...</td>\n",
       "      <td>w210</td>\n",
       "      <td>judge tentatively or form an estimate of (quan...</td>\n",
       "      <td>True</td>\n",
       "      <td>estimate%2:31:00::</td>\n",
       "      <td>estimate.v.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>./semcor3.0/brownv/br-a19.naf</td>\n",
       "      <td>face with a pistol last night after robbing hi...</td>\n",
       "      <td>the_DT face_NN with_IN a_DT pistol_NN last_JJ ...</td>\n",
       "      <td>w225</td>\n",
       "      <td>require as useful, just, or proper</td>\n",
       "      <td>True</td>\n",
       "      <td>need%2:42:00::</td>\n",
       "      <td>necessitate.v.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              file  \\\n",
       "4    ./semcor3.0/brownv/br-a19.naf   \n",
       "8    ./semcor3.0/brownv/br-a19.naf   \n",
       "33   ./semcor3.0/brownv/br-a19.naf   \n",
       "42   ./semcor3.0/brownv/br-a19.naf   \n",
       "62   ./semcor3.0/brownv/br-a19.naf   \n",
       "71   ./semcor3.0/brownv/br-a19.naf   \n",
       "81   ./semcor3.0/brownv/br-a19.naf   \n",
       "85   ./semcor3.0/brownv/br-a19.naf   \n",
       "104  ./semcor3.0/brownv/br-a19.naf   \n",
       "107  ./semcor3.0/brownv/br-a19.naf   \n",
       "135  ./semcor3.0/brownv/br-a19.naf   \n",
       "145  ./semcor3.0/brownv/br-a19.naf   \n",
       "150  ./semcor3.0/brownv/br-a19.naf   \n",
       "161  ./semcor3.0/brownv/br-a19.naf   \n",
       "164  ./semcor3.0/brownv/br-a19.naf   \n",
       "171  ./semcor3.0/brownv/br-a19.naf   \n",
       "179  ./semcor3.0/brownv/br-a19.naf   \n",
       "184  ./semcor3.0/brownv/br-a19.naf   \n",
       "187  ./semcor3.0/brownv/br-a19.naf   \n",
       "202  ./semcor3.0/brownv/br-a19.naf   \n",
       "\n",
       "                                               context  \\\n",
       "4    The Baltimore and Ohio_Railroad yesterday it w...   \n",
       "8    The Baltimore and Ohio_Railroad announced yest...   \n",
       "33   at 12.01 A._M . next Saturday The current mont...   \n",
       "42   15000000 Howard_E._Simpson the railroad 's pre...   \n",
       "62   of heavy goods has necessitated this regrettab...   \n",
       "71   expenses will affect employees in the thirteen...   \n",
       "81   O. operates It will be accomplished in_two_way...   \n",
       "85   accomplished in_two_ways A flat reduction of 1...   \n",
       "104  There are about 3325 officers and employees in...   \n",
       "107  officers and employees in_this class Sufficien...   \n",
       "135  individual union_members under contract it mus...   \n",
       "145  placing some of the men on furlough a B. O. sa...   \n",
       "150  on furlough a B. O. spokesman said Those union...   \n",
       "161  therefore will not take a cut in their wages T...   \n",
       "164  a cut in their wages The spokesman said the nu...   \n",
       "171  number to be furloughed can not be estimated s...   \n",
       "179  the lay-offs must be carried_out in each area ...   \n",
       "184  in each area depending_on what men are most ne...   \n",
       "187  depending_on what men are most needed on_the_j...   \n",
       "202  face with a pistol last night after robbing hi...   \n",
       "\n",
       "                                           context_pos target_word  \\\n",
       "4    The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...          w4   \n",
       "8    The_DT Baltimore_NNP and_CC Ohio_Railroad_NNP ...          w8   \n",
       "33   effective_JJ at_IN 12.01_CD A._M._NNP next_JJ ...         w34   \n",
       "42   15000000_CD Howard_E._Simpson_NNP the_DT railr...         w47   \n",
       "62   of_IN heavy_JJ goods_NNS has_VBZ necessitated_...         w69   \n",
       "71   expenses_NNS will_MD affect_VB employees_NNS i...         w80   \n",
       "81   O._NNP operates_VB It_PRP will_MD be_VB accomp...         w91   \n",
       "85   accomplished_VB in_two_ways_RB A_DT flat_JJ re...         w96   \n",
       "104  There_EX are_VB about_RB 3325_CD officers_NNS ...        w117   \n",
       "107  officers_NNS and_CC employees_NNS in_this_RB c...        w121   \n",
       "135  union_members_NN under_IN contract_NN it_PRP m...        w151   \n",
       "145  placing_VB some_DT of_IN the_DT men_NNS on_IN ...        w162   \n",
       "150  on_IN furlough_NN a_DT B._NNP O._NNP spokesman...        w167   \n",
       "161  jobs_NNS therefore_RB will_MD not_RB take_VB a...        w180   \n",
       "164  take_VB a_DT cut_NN in_IN their_PRP $ wages_NN...        w184   \n",
       "171  said_VB the_DT number_NN to_TO be_VB furloughe...        w193   \n",
       "179  since_IN the_DT lay-offs_NNS must_MD be_VB car...        w202   \n",
       "184  carried_out_VB in_IN each_DT area_NN depending...        w207   \n",
       "187  area_NN depending_on_JJ what_WP men_NNS are_VB...        w210   \n",
       "202  the_DT face_NN with_IN a_DT pistol_NN last_JJ ...        w225   \n",
       "\n",
       "                                                 gloss  is_proper_gloss  \\\n",
       "4                     make known; make an announcement             True   \n",
       "8                     cut down on; make a reduction in             True   \n",
       "33                        add up in number or quantity             True   \n",
       "42                                    express in words             True   \n",
       "62                           cause to be a concomitant             True   \n",
       "71           connect closely and often incriminatingly             True   \n",
       "81       direct or control; projects, businesses, etc.             True   \n",
       "85                                       put in effect             True   \n",
       "104                               be a part or adjunct             True   \n",
       "107                       have an existence, be extant             True   \n",
       "135                   cut down on; make a reduction in             True   \n",
       "145                                      put in effect             True   \n",
       "150  place somebody in a particular situation or lo...             True   \n",
       "161                                   express in words             True   \n",
       "164  keep in a certain state, position, or activity...             True   \n",
       "171               accept or undergo, often unwillingly             True   \n",
       "179                                 report or maintain             True   \n",
       "184              dismiss, usually for economic reasons             True   \n",
       "187  judge tentatively or form an estimate of (quan...             True   \n",
       "202                 require as useful, just, or proper             True   \n",
       "\n",
       "                  wn_index          sense_full  \n",
       "4       announce%2:32:00::       announce.v.01  \n",
       "8         reduce%2:30:00::         reduce.v.01  \n",
       "33          come%2:42:12::          total.v.01  \n",
       "42           say%2:32:00::          state.v.01  \n",
       "62   necessitate%2:42:01::    necessitate.v.02  \n",
       "71        affect%2:42:00::        involve.v.01  \n",
       "81       operate%2:41:00::        operate.v.01  \n",
       "85    accomplish%2:36:00::  carry_through.v.01  \n",
       "104    belong_to%2:42:00::      belong_to.v.01  \n",
       "107           be%2:42:00::          exist.v.01  \n",
       "135       reduce%2:30:00::         reduce.v.01  \n",
       "145   accomplish%2:36:00::  carry_through.v.01  \n",
       "150        place%2:41:01::          place.v.02  \n",
       "161          say%2:32:00::          state.v.01  \n",
       "164         keep%2:42:00::           keep.v.01  \n",
       "171         take%2:31:09::           take.v.19  \n",
       "179          say%2:32:01::         allege.v.01  \n",
       "184     furlough%2:41:00::       furlough.v.01  \n",
       "187     estimate%2:31:00::       estimate.v.01  \n",
       "202         need%2:42:00::    necessitate.v.01  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv \n",
    "data1 = pd.read_csv(\"semcor3.csv\")\n",
    "data2 = pd.read_csv(\"semcor4.csv\")\n",
    "dataset = pd.concat([data1, data2], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/abhishek/miniconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "max_len = 20\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "\n",
    "def create_embeddings(sentences, tokenizer, model, max_length):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # Tokenize each sentence and add special tokens for BERT\n",
    "    for sentence in sentences:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Convert the tokenized input into torch tensors\n",
    "    input_ids = torch.cat(input_ids, dim=0).to(device)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0).to(device)\n",
    "\n",
    "\n",
    "    # Feed the input to BERT and get the embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_masks)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "embeddings = create_embeddings(\n",
    "    X_train['context'], tokenizer, model, max_len)\n",
    "np.save('knn_bert4.npy', embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13305, 768)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = create_embeddings(\n",
    "    X_test['context'], tokenizer, model, max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "XTrain = pd.DataFrame(columns=['file', 'context', 'target_word', 'gloss', 'is_proper_gloss','wn_index'])\n",
    "XTest = pd.DataFrame(columns=['file', 'context', 'target_word', 'gloss', 'is_proper_gloss','wn_index'])\n",
    "\n",
    "XTrain = pd.concat([XTrain, X_train], ignore_index=True)\n",
    "XTest = pd.concat([XTest, X_test], ignore_index=True)\n",
    "\n",
    "XTrain.head(10)\n",
    "\n",
    "cosine_similarities = []\n",
    "zero_cos = 0\n",
    "\n",
    "for i,test_embedding in enumerate(test_embeddings):\n",
    "    test_target_word = XTest.iloc[i]['wn_index']\n",
    "    train_rows = XTrain[XTrain['wn_index'] == test_target_word ]\n",
    "    for j,train_row in train_rows.iterrows():\n",
    "        train_embedding = embeddings[j]\n",
    "        similarity = np.dot(test_embedding, train_embedding) / (np.linalg.norm(test_embedding) * np.linalg.norm(train_embedding))\n",
    "        cosine_similarities.append(similarity)\n",
    "    if len(cosine_similarities) == 0:\n",
    "        zero_cos += 1\n",
    "    if len(cosine_similarities) > 0 :\n",
    "        # without using loc\n",
    "        XTest.at[i, 'cosine_similarity'] = max(cosine_similarities)\n",
    "    else:\n",
    "        # X_test.loc[X_test.index[i], 'cosine_similarity'] = -1\n",
    "        XTest.at[i, 'cosine_similarity'] = -1\n",
    "    cosine_similarities = []\n",
    "\n",
    "\n",
    "XTest['correct'] = XTest.apply(lambda row: row['gloss'] in XTrain[XTrain['wn_index']\n",
    "                                 == row['wn_index']].head(10)['gloss'].tolist(), axis=1)\n",
    "\n",
    "# # print the top-5 glosses of X_train for every X_test row \n",
    "X_test['top_5_glosses'] = X_test.apply(lambda row: X_train[X_train['wn_index'] == row['wn_index']].head(5)['gloss'].tolist(), axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  67.53100338218715\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>context</th>\n",
       "      <th>context_pos</th>\n",
       "      <th>target_word</th>\n",
       "      <th>gloss</th>\n",
       "      <th>is_proper_gloss</th>\n",
       "      <th>wn_index</th>\n",
       "      <th>sense_full</th>\n",
       "      <th>top_5_glosses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6113</th>\n",
       "      <td>./semcor3.0/brown1/br-b13.naf</td>\n",
       "      <td>get_into crevices jacket and crown margins mal...</td>\n",
       "      <td>small_JJ enough_RB to_TO get_into_VB crevices_...</td>\n",
       "      <td>w487</td>\n",
       "      <td>clean with a brush</td>\n",
       "      <td>True</td>\n",
       "      <td>brush%2:35:02::</td>\n",
       "      <td>brush.v.03</td>\n",
       "      <td>[clean with a brush]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>./semcor3.0/brown1/br-k03.naf</td>\n",
       "      <td>love the President like a brother but God_damn...</td>\n",
       "      <td>and_CC pull_down_VB our_PRP $ own_JJ defenses_...</td>\n",
       "      <td>w1842</td>\n",
       "      <td>use or exercise the mind or one's power of rea...</td>\n",
       "      <td>True</td>\n",
       "      <td>think%2:31:00::</td>\n",
       "      <td>think.v.03</td>\n",
       "      <td>[use or exercise the mind or one's power of re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>./semcor3.0/brown1/br-k03.naf</td>\n",
       "      <td>what happened to me today A fellow came_up_to ...</td>\n",
       "      <td>and_CC if_IN you_PRP want_VB to_VB get_along_w...</td>\n",
       "      <td>w1818</td>\n",
       "      <td>a public promotion of some product or service</td>\n",
       "      <td>True</td>\n",
       "      <td>advertising%1:10:00::</td>\n",
       "      <td>ad.n.01</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>./semcor3.0/brown1/br-j57.naf</td>\n",
       "      <td>Christ and still in_use among the truest socie...</td>\n",
       "      <td>book_NN We_PRP find_VB it_PRP in_RB that_RB co...</td>\n",
       "      <td>w796</td>\n",
       "      <td>have the quality of being; (copula, used with ...</td>\n",
       "      <td>True</td>\n",
       "      <td>be%2:42:03::</td>\n",
       "      <td>be.v.01</td>\n",
       "      <td>[have the quality of being; (copula, used with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12278</th>\n",
       "      <td>./semcor3.0/brown1/br-l12.naf</td>\n",
       "      <td>'s just barely possible with this crowd that t...</td>\n",
       "      <td>Skolman_NNP see_VB if_IN some_DT kind_NN of_RB...</td>\n",
       "      <td>w734</td>\n",
       "      <td>happen, occur, take place</td>\n",
       "      <td>True</td>\n",
       "      <td>be%2:42:04::</td>\n",
       "      <td>be.v.05</td>\n",
       "      <td>[happen, occur, take place, happen, occur, tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>./semcor3.0/brown1/br-b13.naf</td>\n",
       "      <td>the sung word is as old as Thomas_Alva_Edison ...</td>\n",
       "      <td>ever_RB before_RB although_IN the_DT spoken_JJ...</td>\n",
       "      <td>w868</td>\n",
       "      <td>grow smaller</td>\n",
       "      <td>True</td>\n",
       "      <td>go_down%2:30:00::</td>\n",
       "      <td>decline.v.04</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7109</th>\n",
       "      <td>./semcor3.0/brown1/br-k16.naf</td>\n",
       "      <td>Its groin was bloody Black strips of skin hung...</td>\n",
       "      <td>thin_JJ legs_NN and_CC its_PRP $ wings_NN were...</td>\n",
       "      <td>w695</td>\n",
       "      <td>a junction where one street or road crosses an...</td>\n",
       "      <td>True</td>\n",
       "      <td>crossroad%1:06:00::</td>\n",
       "      <td>intersection.n.02</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12356</th>\n",
       "      <td>./semcor3.0/brown1/br-l12.naf</td>\n",
       "      <td>Sure I know But it 's such a long_shot No than...</td>\n",
       "      <td>see_eye_to_eye_VB Lieutenant_NN Did_VBD n't_RB...</td>\n",
       "      <td>w938</td>\n",
       "      <td>a human being</td>\n",
       "      <td>True</td>\n",
       "      <td>person%1:03:00::</td>\n",
       "      <td>person.n.01</td>\n",
       "      <td>[a human being, a human being, a human being, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5173</th>\n",
       "      <td>./semcor3.0/brown1/br-k15.naf</td>\n",
       "      <td>baby 's death Juanita drooped about the place ...</td>\n",
       "      <td>the_DT girl_NN tried_VB to_TO insist_VB on_IN ...</td>\n",
       "      <td>w397</td>\n",
       "      <td>develop (children's) behavior by instruction a...</td>\n",
       "      <td>True</td>\n",
       "      <td>discipline%2:41:01::</td>\n",
       "      <td>discipline.v.01</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11199</th>\n",
       "      <td>./semcor3.0/brown1/br-k01.naf</td>\n",
       "      <td>the food a topic The blueberry_pie is good Sco...</td>\n",
       "      <td>and_CC the_DT bright_JJ ranks_NN of_IN college...</td>\n",
       "      <td>w283</td>\n",
       "      <td>any substance that can be metabolized by an an...</td>\n",
       "      <td>True</td>\n",
       "      <td>food%1:03:00::</td>\n",
       "      <td>food.n.01</td>\n",
       "      <td>[any substance that can be metabolized by an a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                file  \\\n",
       "6113   ./semcor3.0/brown1/br-b13.naf   \n",
       "2453   ./semcor3.0/brown1/br-k03.naf   \n",
       "2442   ./semcor3.0/brown1/br-k03.naf   \n",
       "2859   ./semcor3.0/brown1/br-j57.naf   \n",
       "12278  ./semcor3.0/brown1/br-l12.naf   \n",
       "6298   ./semcor3.0/brown1/br-b13.naf   \n",
       "7109   ./semcor3.0/brown1/br-k16.naf   \n",
       "12356  ./semcor3.0/brown1/br-l12.naf   \n",
       "5173   ./semcor3.0/brown1/br-k15.naf   \n",
       "11199  ./semcor3.0/brown1/br-k01.naf   \n",
       "\n",
       "                                                 context  \\\n",
       "6113   get_into crevices jacket and crown margins mal...   \n",
       "2453   love the President like a brother but God_damn...   \n",
       "2442   what happened to me today A fellow came_up_to ...   \n",
       "2859   Christ and still in_use among the truest socie...   \n",
       "12278  's just barely possible with this crowd that t...   \n",
       "6298   the sung word is as old as Thomas_Alva_Edison ...   \n",
       "7109   Its groin was bloody Black strips of skin hung...   \n",
       "12356  Sure I know But it 's such a long_shot No than...   \n",
       "5173   baby 's death Juanita drooped about the place ...   \n",
       "11199  the food a topic The blueberry_pie is good Sco...   \n",
       "\n",
       "                                             context_pos target_word  \\\n",
       "6113   small_JJ enough_RB to_TO get_into_VB crevices_...        w487   \n",
       "2453   and_CC pull_down_VB our_PRP $ own_JJ defenses_...       w1842   \n",
       "2442   and_CC if_IN you_PRP want_VB to_VB get_along_w...       w1818   \n",
       "2859   book_NN We_PRP find_VB it_PRP in_RB that_RB co...        w796   \n",
       "12278  Skolman_NNP see_VB if_IN some_DT kind_NN of_RB...        w734   \n",
       "6298   ever_RB before_RB although_IN the_DT spoken_JJ...        w868   \n",
       "7109   thin_JJ legs_NN and_CC its_PRP $ wings_NN were...        w695   \n",
       "12356  see_eye_to_eye_VB Lieutenant_NN Did_VBD n't_RB...        w938   \n",
       "5173   the_DT girl_NN tried_VB to_TO insist_VB on_IN ...        w397   \n",
       "11199  and_CC the_DT bright_JJ ranks_NN of_IN college...        w283   \n",
       "\n",
       "                                                   gloss  is_proper_gloss  \\\n",
       "6113                                  clean with a brush             True   \n",
       "2453   use or exercise the mind or one's power of rea...             True   \n",
       "2442       a public promotion of some product or service             True   \n",
       "2859   have the quality of being; (copula, used with ...             True   \n",
       "12278                          happen, occur, take place             True   \n",
       "6298                                        grow smaller             True   \n",
       "7109   a junction where one street or road crosses an...             True   \n",
       "12356                                      a human being             True   \n",
       "5173   develop (children's) behavior by instruction a...             True   \n",
       "11199  any substance that can be metabolized by an an...             True   \n",
       "\n",
       "                    wn_index         sense_full  \\\n",
       "6113         brush%2:35:02::         brush.v.03   \n",
       "2453         think%2:31:00::         think.v.03   \n",
       "2442   advertising%1:10:00::            ad.n.01   \n",
       "2859            be%2:42:03::            be.v.01   \n",
       "12278           be%2:42:04::            be.v.05   \n",
       "6298       go_down%2:30:00::       decline.v.04   \n",
       "7109     crossroad%1:06:00::  intersection.n.02   \n",
       "12356       person%1:03:00::        person.n.01   \n",
       "5173    discipline%2:41:01::    discipline.v.01   \n",
       "11199         food%1:03:00::          food.n.01   \n",
       "\n",
       "                                           top_5_glosses  \n",
       "6113                                [clean with a brush]  \n",
       "2453   [use or exercise the mind or one's power of re...  \n",
       "2442                                                  []  \n",
       "2859   [have the quality of being; (copula, used with...  \n",
       "12278  [happen, occur, take place, happen, occur, tak...  \n",
       "6298                                                  []  \n",
       "7109                                                  []  \n",
       "12356  [a human being, a human being, a human being, ...  \n",
       "5173                                                  []  \n",
       "11199  [any substance that can be metabolized by an a...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracy = XTest['correct'].sum() / len(XTest)\n",
    "print(\"Accuracy: \", accuracy*100)\n",
    "X_test.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8941\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "data = pd.read_csv(\"semcor3.csv\")\n",
    "print(len(data))\n",
    "test_data = data[:500]\n",
    "train_data = data[500:]\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "# Compute BERT embeddings for each sentence and target word\n",
    "embeddings = []\n",
    "for i, row in data.iterrows():\n",
    "    context = row['context']\n",
    "    context_pos = row['context_pos']\n",
    "    # print(len(context_pos.split()))\n",
    "    target_word = row['sense_full']\n",
    "    gloss = row['gloss']\n",
    "    tokens = tokenizer.encode(context, target_word, add_special_tokens=False)\n",
    "    pos_tag_tokens = tokenizer.encode(context, add_special_tokens=False)\n",
    "    # shuffle the pos_tag_tokens list\n",
    "    np.random.shuffle(pos_tag_tokens)\n",
    "    gloss_tokens = tokenizer.encode(gloss, add_special_tokens=False)\n",
    "    tokens = tokens + [tokenizer.sep_token_id] + gloss_tokens \n",
    "\n",
    "    input_ids = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "    pos_tag_ids = torch.tensor(pos_tag_tokens).unsqueeze(0).to(device)\n",
    "    # Compute BERT embeddings\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)\n",
    "        context_embedding = output[0][0][1:-1].mean(dim=0).cpu()\n",
    "        pos_embedding = model(pos_tag_ids)[0][0][1:-1].mean(dim=0).cpu()\n",
    "\n",
    "    embedding = torch.cat([context_embedding, pos_embedding], dim=0).cpu().numpy()\n",
    "    embeddings.append(embedding) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the embeddings\n",
    "# embedding = embeddings.cpu().numpy()\n",
    "np.save('naive_bert_embeddings.npy', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train = np.array(embeddings)\n",
    "y_train = data['wn_index'].values\n",
    "# print(x_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = embeddings[:500]\n",
    "x_test = np.array(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_probs = {}\n",
    "likelihoods = {}\n",
    "y_test = test_data['wn_index'].values\n",
    "\n",
    "for sense in set(y_train):\n",
    "    sense_count = sum(y_train == sense)\n",
    "    # print(sense,sense_count)\n",
    "    prior_probs[sense] = sense_count / len(y_train)   \n",
    "    sense_embeddings = [x_train[i] for i in range(len(x_train)) if y_train[i] == sense]\n",
    "    likelihoods[sense] = np.mean(sense_embeddings, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(0,len(y_test)):\n",
    "    max_prob = 0\n",
    "    max_sense = None\n",
    "    for sense in set(y_train):\n",
    "        log_prob = prior_probs[sense]\n",
    "        # print(log_prob)\n",
    "        for j in range(len(x_test[i])):\n",
    "            log_prob = log_prob + x_test[i][j] * likelihoods[sense][j]\n",
    "        if log_prob > max_prob:\n",
    "            max_prob = log_prob\n",
    "            max_sense = sense\n",
    "    y_pred.append(max_sense)\n",
    "\n",
    "accuracy = sum(y_pred[i] == y_test.tolist()[i]\n",
    "               for i in range(len(y_test)))/len(y_test)  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy with context + poss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.2\n"
     ]
    }
   ],
   "source": [
    "print(accuracy*100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy with context as only feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad0a8d25012454fce516fd02556d13b58ba350644df31d02f07d47f8074eb7a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
